{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23f6a744",
   "metadata": {
    "id": "23f6a744"
   },
   "source": [
    "Imports necessary libraries: numpy for numerical operations, cv2 for OpenCV functions, sys for system-specific parameters and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37fa554d",
   "metadata": {
    "id": "37fa554d"
   },
   "outputs": [],
   "source": [
    "import numpy as np                    #complete this\n",
    "import sys                    #complete this\n",
    "import cv2  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87afea9a",
   "metadata": {
    "id": "87afea9a"
   },
   "source": [
    "Defines colors for text and border using random RGB values, sets a font for text, and specifies the path to the video source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c5e73b6",
   "metadata": {
    "id": "0c5e73b6"
   },
   "outputs": [],
   "source": [
    "TEXT_COLOR = (0, 255, 0)\n",
    "TRACKER_COLOR = (255, 0, 0)\n",
    "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "VIDEO_SOURCE = \"Animal_1.mp4\"             #complete this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bf34bf",
   "metadata": {
    "id": "14bf34bf"
   },
   "source": [
    "Lists the types of background subtraction methods available. reference: https://stackoverflow.com/questions/33266239/differences-between-mog-mog2-and-gmg-in-opencv-cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "81f5e249",
   "metadata": {
    "id": "81f5e249"
   },
   "outputs": [],
   "source": [
    "BGS_TYPES = [\"GMG\", \"MOG\", \"MOG2\", \"KNN\", \"CNT\"]             #complete this\n",
    "BGS_TYPE = BGS_TYPES[2]       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c62ac1",
   "metadata": {
    "id": "a3c62ac1"
   },
   "source": [
    "Defines a function to get different types of kernels (structuring elements) used in morphological transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1dca93ca",
   "metadata": {
    "id": "1dca93ca"
   },
   "outputs": [],
   "source": [
    "def getKernel(KERNEL_TYPE):\n",
    "    if KERNEL_TYPE == \"dilation\":\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    if KERNEL_TYPE == \"opening\":\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "    if KERNEL_TYPE == \"closing\":\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efe1cfb",
   "metadata": {
    "id": "9efe1cfb"
   },
   "source": [
    "Applies specified morphological operations to an image, like closing, opening, or dilation, and returns the modified image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "95c7b2f3",
   "metadata": {
    "id": "95c7b2f3"
   },
   "outputs": [],
   "source": [
    "def getFilter(img, filter):\n",
    "    if filter == 'closing':\n",
    "        return cv2.morphologyEx(img, cv2.MORPH_CLOSE, getKernel(\"closing\"), iterations=1)\n",
    "\n",
    "    if filter == 'opening':\n",
    "        return cv2.morphologyEx(img, cv2.MORPH_OPEN, getKernel(\"opening\"), iterations=1)\n",
    "\n",
    "    if filter == 'dilation':\n",
    "        return cv2.dilate(img, getKernel(\"dilation\"), iterations=2)\n",
    "\n",
    "    if filter == 'combine':\n",
    "        closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, getKernel(\"closing\"), iterations=1)\n",
    "        opening = cv2.morphologyEx(closing, cv2.MORPH_OPEN, getKernel(\"opening\"), iterations=1)\n",
    "        dilation = cv2.dilate(opening, getKernel(\"dilation\"), iterations=1)\n",
    "\n",
    "        return dilation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb11f4ed",
   "metadata": {
    "id": "fb11f4ed"
   },
   "source": [
    "Based on the type (BGS_TYPE), it initializes and returns a background subtractor object. Each type corresponds to a different algorithm for background subtraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d55a46e6",
   "metadata": {
    "id": "d55a46e6"
   },
   "outputs": [],
   "source": [
    "def getBGSubtractor(BGS_TYPE):\n",
    "    if BGS_TYPE == \"GMG\":                                     #complete this\n",
    "        return cv2.bgsegm.createBackgroundSubtractorGMG()\n",
    "    if BGS_TYPE == \"MOG\":                                     #complete this\n",
    "        return cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "    if BGS_TYPE == \"MOG2\":                                     #complete this\n",
    "        return cv2.createBackgroundSubtractorMOG2()\n",
    "    if BGS_TYPE == \"KNN\":                                     #complete this\n",
    "        return cv2.createBackgroundSubtractorKNN()\n",
    "    if BGS_TYPE == \"CNT\":                                     #complete this\n",
    "        return cv2.bgsegm.createBackgroundSubtractorCNT()\n",
    "    print(\"Invalid detector\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbd90ac",
   "metadata": {
    "id": "cdbd90ac"
   },
   "source": [
    "Prepare the video for processing, initialize the background subtractor, and set a minimum area for detected objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "daf7a42c",
   "metadata": {
    "id": "daf7a42c"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(VIDEO_SOURCE)                                            #complete this\n",
    "bg_subtractor = getBGSubtractor(BGS_TYPE)\n",
    "minArea = 250                                       #complete this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b54b79",
   "metadata": {
    "id": "d6b54b79"
   },
   "source": [
    "This function contains the main loop for processing the video:\n",
    "\n",
    "1.Read and Resize Frame: Each frame of the video is read and resized for processing efficiency.<br>\n",
    "2.Apply Background Subtraction: The selected background subtraction method is applied to separate moving objects from the background.<br>\n",
    "3.Morphological Filtering: The background mask is cleaned up using a combination of morphological operations to improve the detection of moving objects.<br>\n",
    "4.Find Contours: Contours of moving objects are detected in the filtered mask.<br>\n",
    "5.Drawing and Display: For each detected object with an area larger than minArea, the script dynamically draws a semi-transparent overlay on the original frame to highlight the object.<br>\n",
    "6.Display Results: The processed frame and the mask are displayed in separate windows.<br>\n",
    "7.Exit Condition: The loop can be exited by pressing the \"q\" key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8c6e19de",
   "metadata": {
    "id": "8c6e19de"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    while (cap.isOpened):\n",
    "        ok, frame = cap.read()                              \n",
    "        if not ok:\n",
    "            print(\"Finished processing the video\")\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "        frame = cv2.resize(frame, (0, 0), fx=0.50, fy=0.50)\n",
    "\n",
    "        bg_mask = bg_subtractor.apply(frame)\n",
    "        bg_mask = getFilter(bg_mask, 'combine')\n",
    "        bg_mask = cv2.medianBlur(bg_mask, 5)\n",
    "\n",
    "        (contours, hierarchy) = cv2.findContours(bg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        #print(contours)\n",
    "        for cnt in contours:\n",
    "            area = cv2.contourArea(cnt)\n",
    "            if area >= minArea:\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                cv2.rectangle(frame, (10,30), (250,55), (255,0,0), -1)\n",
    "                cv2.putText(frame, 'Motion Detected', (10,50), FONT, 0.8, TEXT_COLOR, 2, cv2.LINE_AA)             #put any alert msg e.g. Motion detected!\n",
    "\n",
    "                #Rectangle\n",
    "                cv2.rectangle(frame, (x,y), (x+w, y+h), (255, 0, 0), 3)\n",
    "\n",
    "                #Countour\n",
    "                #cv2.drawContours(frame, cnt, -1, (0,0,255), 3)\n",
    "\n",
    "                #https://www.pyimagesearch.com/2016/03/07/transparent-overlays-with-opencv/\n",
    "                # for alpha in np.arange(0.8, 1.1, 0.9)[::-1]:\n",
    "                #     frame_copy = frame.copy()\n",
    "                #     output = frame.copy()\n",
    "                #     cv2.drawContours(frame_copy, [cnt], -1, TRACKER_COLOR, -1)\n",
    "                #     frame = cv2.addWeighted(frame_copy, alpha, output, 1 - alpha, 0, output)\n",
    "\n",
    "\n",
    "        result = cv2.bitwise_and(frame, frame, mask=bg_mask)\n",
    "        cv2.imshow('Frame', frame)\n",
    "        cv2.imshow('Mask', result)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a9a966",
   "metadata": {
    "id": "b3a9a966"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
